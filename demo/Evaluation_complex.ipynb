{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "529978ac",
   "metadata": {},
   "source": [
    "# Prepare Enviroment\n",
    "\n",
    "this notebook will show the evaluation results of our algorithms on Fig4.e complex scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90801071",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff60e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use %autoreload command to reload all libraries\n",
    "%autoreload\n",
    "import sys\n",
    "sys.path.append(\"./YOLOPv1\")\n",
    "sys.path.append(\"./YOLOv5\")\n",
    "sys.path.append(\"./datareader\")\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import argparse, time, os, random\n",
    "from math import log10\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a34baf",
   "metadata": {},
   "source": [
    "# prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28545890",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "from tianmoucv.alg import cal_optical_flow,flow_to_image\n",
    "from tianmoucv.nn import compute_iou\n",
    "\n",
    "from opticalFilter import opticalDetector_Maxone\n",
    "from YOLOPv1detector import YOLOPv1detector\n",
    "from YOLOv5detector import YOLOv5detector_SD \n",
    "from KalmanTrackor import * \n",
    "from opticalFilter import opticalDetector_Maxone\n",
    "\n",
    "detectorPv1 = YOLOPv1detector(path = '../data/ckpts/yolopv1_170e.pth')\n",
    "detectorPv1._get_normalizer(mean=[0.39556265,0.42169937,0.65865874],\n",
    "                            std=[0.18127572356817837,0.261213080783536,0.6503947447629356])\n",
    "\n",
    "detectorv5 =YOLOv5detector_SD(path = '../data/ckpts/YOLOv5_400e_320x160_fp32trained.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d53496",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15188756",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import struct\n",
    "import cv2,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from tianmoucv.isp import lyncam_raw_comp,demosaicing_npy\n",
    "sys.path.append(\"../datareader\")\n",
    "\n",
    "# an easy data read tool\n",
    "def read_data(dataset,key,idx):\n",
    "    sample = dict([])\n",
    "\n",
    "    itter = 26\n",
    "    rgb_processed,_,_,_,old_conetimeStamp,conefilename = dataset.readFile(key,idx,0,viz=False,ifSync =True)\n",
    "    rgb_processed = lyncam_raw_comp(rgb_processed)\n",
    "    rgb = demosaicing_npy(rgb_processed, 'bggr', 1, 10)/1024\n",
    "    sample['F0'] = torch.FloatTensor(rgb).permute(2,0,1)\n",
    "    rgb_processed,_,_,_,new_conetimeStamp,_ = dataset.readFile(key,idx+1,0,viz=False,ifSync =True)\n",
    "    rgb_processed = lyncam_raw_comp(rgb_processed)\n",
    "    rgb = demosaicing_npy(rgb_processed, 'bggr', 1, 10)/1024\n",
    "    sample['F1'] = torch.FloatTensor(rgb).permute(2,0,1)\n",
    "    tsd = torch.zeros([3,itter,160,320])\n",
    "    gap = 0\n",
    "    mingap = 0\n",
    "    maxgap = 0\n",
    "    bias = -2\n",
    "    for i in range(-3,3):\n",
    "        bias = i\n",
    "        _,tdt,sdt,rodtimeStamp,_,_ = dataset.readFile(key,start,idx*(25)+0+bias,viz=False,ifSync =True)\n",
    "        mingap = abs(old_conetimeStamp-rodtimeStamp)  \n",
    "        _,tdt,sdt,rodtimeStamp,_,_ = dataset.readFile(key,start,idx*(25)+itter-1+bias,viz=False,ifSync =True)\n",
    "        maxgap = abs(new_conetimeStamp-rodtimeStamp)\n",
    "        if maxgap < 130 or mingap<130:\n",
    "            #print('bias:',bias)\n",
    "            break\n",
    "\n",
    "    for i in range(itter):\n",
    "        _,tdt,sdt,rodtimeStamp,_,_ = dataset.readFile(key,start,idx*(25)+i+bias,viz=False,ifSync =True)\n",
    "        if i == 0:\n",
    "            mingap = abs(old_conetimeStamp-rodtimeStamp) \n",
    "        if i == itter-1:\n",
    "            maxgap = abs(new_conetimeStamp-rodtimeStamp) \n",
    "        sdt = sdt.permute(2,0,1)\n",
    "        td_inter = F.interpolate(tdt.unsqueeze(0).unsqueeze(0), \n",
    "                                               (tdt.shape[0],tdt.shape[1]*2), mode='bilinear')\n",
    "        sd_inter = F.interpolate(sdt.unsqueeze(0), (sdt.shape[1],sdt.shape[2]*2), mode='bilinear')\n",
    "        td_inter = td_inter.squeeze(0).squeeze(0)\n",
    "        sd_inter = sd_inter.squeeze(0)\n",
    "        tsd[0,i,:,:] = td_inter\n",
    "        tsd[1:3,i,:,:] = sd_inter\n",
    "\n",
    "    sample['tsdiff'] = tsd\n",
    "    if maxgap > 30 or mingap>30:\n",
    "        print('missing sample:',maxgap,mingap)\n",
    "        return -1\n",
    "    #print(cone,'/',dataset.dataNum(key),'--',key,' sync time gap:',maxgap,'/',mingap,'us')\n",
    "    #filename = savePath + '/' + key + '_'+ str(cone) + '.npy'\n",
    "    #np.save(filename, sample)\n",
    "    return sample,conefilename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82849266",
   "metadata": {},
   "source": [
    "# Evaluate the algorithm\n",
    "\n",
    "- the ground truth is the sparse reconstructed rgb frames\n",
    "- COP:YOLOP *blue box is COP results*\n",
    "- AOP:YOLOv5+optical flow filter *red box is COP results*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9aa563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.callbacks import Callbacks\n",
    "from utils.dataloaders import create_dataloader\n",
    "from utils.general import (LOGGER, check_dataset, check_img_size, check_requirements, check_yaml,\n",
    "                           coco80_to_coco91_class, colorstr, emojis, increment_path, print_args,\n",
    "                           scale_coords, xywh2xyxy, xyxy2xywh)\n",
    "from utils.metrics import ConfusionMatrix, ap_per_class, box_iou\n",
    "from utils.plots import output_to_target, plot_images, plot_val_study\n",
    "from utils.torch_utils import select_device, time_sync\n",
    "from libs.core.general import non_max_suppression\n",
    "\n",
    "\n",
    "# test if it is a correct detction under a given mIOU threshold\n",
    "def process_batch(detections, labels, iouv):\n",
    "    \"\"\"\n",
    "    Return correct predictions matrix. Both sets of boxes are in (x1, y1, x2, y2) format.\n",
    "    Arguments:\n",
    "        detections (Array[N, 6]), x1, y1, x2, y2, conf, class\n",
    "        labels (Array[M, 5]), class, x1, y1, x2, y2\n",
    "    Returns:\n",
    "        correct (Array[N, 10]), for 10 IoU levels\n",
    "    \"\"\"\n",
    "    correct = np.zeros((detections.shape[0], iouv.shape[0])).astype(bool)\n",
    "    iou = box_iou(labels[:, 1:], detections[:, :4])\n",
    "    correct_class = labels[:, 0:1] == detections[:, 5]\n",
    "    for i in range(len(iouv)):\n",
    "        x = torch.where((iou >= iouv[i]) & correct_class)  # IoU > threshold and classes match\n",
    "        if x[0].shape[0]:\n",
    "            matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1).cpu().numpy()  # [label, detect, iou]\n",
    "            if x[0].shape[0] > 1:\n",
    "                matches = matches[matches[:, 2].argsort()[::-1]]\n",
    "                matches = matches[np.unique(matches[:, 1], return_index=True)[1]]\n",
    "                # matches = matches[matches[:, 2].argsort()[::-1]]\n",
    "                matches = matches[np.unique(matches[:, 0], return_index=True)[1]]\n",
    "            correct[matches[:, 1].astype(int), i] = True\n",
    "    return torch.tensor(correct, dtype=torch.bool, device=iouv.device)\n",
    "\n",
    "evaluate = True\n",
    "single_cls = True # if only single class\n",
    "addOpticalFlow = False # if add optical flow filter on AOP\n",
    " \n",
    "# OF need raw file\n",
    "rawdataset = None\n",
    "\n",
    "if addOpticalFlow:\n",
    "    import rawDataReadTool as rdrt\n",
    "    rawdataset = rdrt.TianmoucDataRead(8,dataset_top = \"../data/recon_data\")\n",
    "\n",
    "count = 0\n",
    "#Choose sample\n",
    "key ='fig4b'  \n",
    "key ='fig4c'  \n",
    "key ='fig4d'  \n",
    "key ='fig4e' \n",
    "key ='fig4a'  \n",
    "\n",
    "evaluationPath = '../data/demo_data/'+key\n",
    "\n",
    "accumTime = 1\n",
    "dataList = os.listdir(evaluationPath + '/raw') \n",
    "optifilt = opticalDetector_Maxone(noiseThresh = 1.6*accumTime,distanceThresh=0.2)\n",
    "\n",
    "SDstate = []\n",
    "RGBstate = []\n",
    "Hybridstate = []\n",
    "single_cls = True\n",
    "count = 0\n",
    "print(dataList)\n",
    "\n",
    "imlist = []\n",
    "\n",
    "for filename in dataList:\n",
    "    labelsList = []\n",
    "    labelfile = None\n",
    "    sample = None\n",
    "\n",
    "    filename = filename.split('.')[0]\n",
    "    RawName = evaluationPath + '/raw/' + filename + '.npy'\n",
    "    labelName = evaluationPath + '/label/' + filename + '.txt'\n",
    "    sample = np.load(RawName,allow_pickle=True).item()\n",
    "    labelfile = open(labelName,'r')  \n",
    "\n",
    "    file_data = labelfile.readlines() \n",
    "    for row in file_data:\n",
    "        tmp_list = row.split(' ') \n",
    "        labelsList.append([float(e) for e in tmp_list]) \n",
    "    \n",
    "    if evaluate:\n",
    "        count +=1 \n",
    "        \n",
    "        #cop0,cop1,aop0~26\n",
    "        F0,F1,tsdiff = sample['F0'],sample['F1'],sample['tsdiff']\n",
    "        \n",
    "        \n",
    "        F0_batch = torch.zeros([1,3,320,640])\n",
    "        F0_batch[0,...] = F0\n",
    "        sd_imlist = []\n",
    "        sd_detect = []\n",
    "        SDtargets = torch.zeros([len(labelsList),6]).to(detectorv5.model.device)\n",
    "        RGBtargets = torch.zeros([len(labelsList),6]).to(detectorPv1.device)\n",
    "        HybTargets = torch.zeros([len(labelsList),6]).to(detectorPv1.device)\n",
    "        for i in range(len(labelsList)):\n",
    "            cls,x,y,w,h = labelsList[i]\n",
    "            if single_cls:\n",
    "                cls = 0\n",
    "            SDtargets[i,1:]=torch.FloatTensor([cls,x*320,y*160,w*320,h*160])\n",
    "            RGBtargets[i,1:]=torch.FloatTensor([cls,x*640,y*320,w*640,h*320])\n",
    "            HybTargets[i,1:]=torch.FloatTensor([cls,x*640,y*320,w*640,h*320])\n",
    "        \n",
    "        #===========Only single COP===========\n",
    "        iouv = torch.linspace(0.5, 0.95, 10, device=detectorPv1.device)  # iou vector for mAP@0.5:0.95\n",
    "        niou = iouv.numel()\n",
    "        F0_batch = F0_batch.to(detectorPv1.device)\n",
    "        img_det,img_seg_safe,img_seg_line,RGBpred,RGBout = detectorPv1(F0_batch)\n",
    "        si = 0\n",
    "        if single_cls:\n",
    "            RGBpred[:, 5] = 0\n",
    "        labels = RGBtargets[RGBtargets[:, 0] == si, 1:]\n",
    "        nl, npr = RGBtargets.shape[0], RGBpred.shape[0]  # number of labels, predictions\n",
    "        correct = torch.zeros(npr, niou, dtype=torch.bool, device=detectorPv1.device)  # init\n",
    "        if npr == 0:\n",
    "            if nl:\n",
    "                RGBstate.append((correct, *torch.zeros((2, 0), device=detectorPv1.device), labels[:, 0]))\n",
    "        # Predictions\n",
    "        predn = RGBpred.clone()\n",
    "        # Evaluate\n",
    "        if nl:\n",
    "            tbox = xywh2xyxy(labels[:, 1:5])  # target boxes\n",
    "            labelsn = torch.cat((labels[:, 0:1], tbox), 1)  # native-space labels\n",
    "            correct = process_batch(predn, labelsn, iouv)\n",
    "        RGBstate.append((correct, RGBpred[:, 4], RGBpred[:, 5], labels[:, 0]))  # (correct, conf, pcls, tcls)\n",
    "        \n",
    "        #===========Only single AOP===========\n",
    "        for t in range(1,26):\n",
    "            iouv = torch.linspace(0.5, 0.95, 10, device=detectorv5.device)  # iou vector for mAP@0.5:0.95\n",
    "            niou = iouv.numel()\n",
    "            SD_batch = tsdiff[1:,t,...].unsqueeze(0)\n",
    "            SD_batch = SD_batch.to(detectorv5.model.device) \n",
    "            SD_show = torch.cat([tsdiff[1:,t,...],torch.zeros(1,160,320)],dim=0) / 128.0\n",
    "            SD_show = np.ascontiguousarray(SD_show.permute(1,2,0).numpy())\n",
    "            SDpreds,SDout = detectorv5(SD_batch,SD_show)\n",
    "            SDpred = SDpreds[0]\n",
    "            #=========== add OF filter, if have raw data===========\n",
    "            if addOpticalFlow:\n",
    "                cone_id = count\n",
    "                sd = 0\n",
    "                td = 0\n",
    "                for i in range(accumTime):\n",
    "\n",
    "                    rgb,tdt,sdt,rodtimeStamp,conetimeStamp ,_= rawdataset.readFile(key,cone_id ,cone_id *(25)+t+i\n",
    "                                                                                ,viz=False,ifSync =False)\n",
    "                    Ix = np.zeros(tdt.shape)\n",
    "                    Iy = np.zeros(tdt.shape)\n",
    "                    sdul = sdt[0::2,...,0]\n",
    "                    sdll = sdt[1::2,...,0]\n",
    "                    sdur = sdt[0::2,...,1]\n",
    "                    sdlr = sdt[1::2,...,1]\n",
    "                    Ix[::2,...] = Ix[1::2,...]= (-(sdul + sdll)/1.414 + (sdur + sdlr)/1.414)/2\n",
    "                    Iy[1::2,...]= Iy[::2,...] = ((sdur - sdlr)/1.414 + (sdul - sdll)/1.414)/2\n",
    "                    sd += torch.FloatTensor(np.stack([Ix,Iy],axis=2))\n",
    "                    td += -tdt\n",
    "                    \n",
    "                sd = sd.permute(2,0,1)\n",
    "                td = td.unsqueeze(0)\n",
    "                box,area,flowup = optifilt(sd,td)\n",
    "                if not box is None:\n",
    "                    x1,y1,x2,y2 = box\n",
    "                    opticalDetection = torch.zeros([1,6],device=SDpred.device)\n",
    "                    opticalDetection[0,0] = x1/2.0\n",
    "                    opticalDetection[0,1] = y1/2.0\n",
    "                    opticalDetection[0,2] = x2/2.0\n",
    "                    opticalDetection[0,3] = y2/2.0\n",
    "                    opticalDetection[0,4] = 1\n",
    "                    opticalDetection[0,5] = 0\n",
    "                    SDpred = torch.cat([SDpred,opticalDetection],dim=0)\n",
    "                    cv2.rectangle(img_det, (int(x1),int(y1)), (int(x2),int(y2)), (139, 0, 0), 2)\n",
    "            #print('SD output shape:',SDout.shape)\n",
    "\n",
    "            \n",
    "            canvas = np.zeros([img_det.shape[0],img_det.shape[1]*3,3])\n",
    "            canvas[:,:img_det.shape[1],:] = img_det\n",
    "            canvas[:,img_det.shape[1]:2*img_det.shape[1],:] = img_seg_safe + img_seg_line\n",
    "            SD_show = 1 - SD_show\n",
    "            canvas[:,2*img_det.shape[1]:,:] = cv2.resize(SD_show,(640,320))\n",
    "            for i in range(SDpred.shape[0]):\n",
    "                x1 = int(SDpred[0,0]*2)\n",
    "                y1 = int(SDpred[0,1]*2)\n",
    "                x2 = int(SDpred[0,2]*2)\n",
    "                y2 = int(SDpred[0,3]*2)\n",
    "                cv2.rectangle(canvas, (int(x1),int(y1)), (int(x2),int(y2)), (139, 0, 0), 2)\n",
    "            canvas[canvas>=1] = 1\n",
    "            imlist.append(canvas)\n",
    "            if t==12:\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "                plt.axis('off')\n",
    "                plt.imshow(canvas)\n",
    "                plt.show()\n",
    "            \n",
    "            si = 0\n",
    "            if single_cls:\n",
    "                SDpred[:, 5] = 0\n",
    "            labels = SDtargets[SDtargets[:, 0] == si, 1:]\n",
    "            nl, npr = SDtargets.shape[0], SDpred.shape[0]  # number of labels, predictions\n",
    "            correct = torch.zeros(npr, niou, dtype=torch.bool, device=detectorv5.device)  # init\n",
    "            if npr == 0:\n",
    "                if nl:\n",
    "                    SDstate.append((correct, *torch.zeros((2, 0), device=detectorv5.device), labels[:, 0]))\n",
    "                continue\n",
    "            # Predictions\n",
    "            predn = SDpred.clone()\n",
    "            # Evaluate\n",
    "            if nl:\n",
    "                tbox = xywh2xyxy(labels[:, 1:5])  # target boxes\n",
    "                labelsn = torch.cat((labels[:, 0:1], tbox), 1)  # native-space labels\n",
    "                correct = process_batch(predn, labelsn, iouv)\n",
    "            SDstate.append((correct, SDpred[:, 4], SDpred[:, 5], labels[:, 0]))  # (correct, conf, pcls, tcls)\n",
    "\n",
    "            #=========== complement algorithm results with NMS ===========\n",
    "            SDoutClass = torch.zeros([1,SDout.shape[1],6]).to(detectorPv1.device)\n",
    "            SDoutClass[:,:,:4] =  SDout[:,:,:4]*2\n",
    "            SDoutClass[:,:,4] = SDout[:,:,4]\n",
    "            _,SDoutClass[:,:,5] = torch.max(SDout[:,:,5:],dim=-1)\n",
    "            \n",
    "            hybout = torch.cat([SDoutClass,RGBout],dim=1)\n",
    "            hybridPred = non_max_suppression(hybout, 0.5, 0.5)[0]\n",
    "\n",
    "            iouv = torch.linspace(0.5, 0.95, 10, device=detectorPv1.device)  # iou vector for mAP@0.5:0.95\n",
    "            niou = iouv.numel()\n",
    "            si = 0\n",
    "            if single_cls:\n",
    "                hybridPred[:, 5] = 0\n",
    "            labels = HybTargets[HybTargets[:, 0] == si, 1:]\n",
    "            nl, npr = HybTargets.shape[0], hybridPred.shape[0]  # number of labels, predictions\n",
    "            correct = torch.zeros(npr, niou, dtype=torch.bool, device=detectorPv1.device)  # init\n",
    "            if npr == 0:\n",
    "                if nl:\n",
    "                    Hybridstate.append((correct, *torch.zeros((2, 0), device=detectorPv1.device), labels[:, 0]))\n",
    "                continue\n",
    "            # Predictions\n",
    "            predn = hybridPred.clone()\n",
    "            if nl:\n",
    "                tbox = xywh2xyxy(labels[:, 1:5])  # target boxes\n",
    "                labelsn = torch.cat((labels[:, 0:1], tbox), 1)  # native-space labels\n",
    "                correct = process_batch(predn, labelsn, iouv)\n",
    "            Hybridstate.append((correct, hybridPred[:, 4], hybridPred[:, 5], labels[:, 0]))  # (correct, conf, pcls, tcls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9340378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('                MP              MR                  MAP50             map5_95' )\n",
    "\n",
    "stats = [torch.cat(x, 0).cpu().numpy() for x in zip(*SDstate)]  # to numpy\n",
    "if len(stats) and stats[0].any():\n",
    "    tp, fp, p, r, f1, ap, ap_class = ap_per_class(*stats, plot=False, save_dir=None, names={'name':'yolov5s'})\n",
    "    ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95\n",
    "    mp, mr, map50, map5_95 = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
    "    print('AOP:',mp, mr, map50,map5_95)\n",
    "    \n",
    "stats = [torch.cat(x, 0).cpu().numpy() for x in zip(*RGBstate)]  # to numpy\n",
    "if len(stats) and stats[0].any():\n",
    "    tp, fp, p, r, f1, ap, ap_class = ap_per_class(*stats, plot=False, save_dir=None, names={'name':'yolov5s'})\n",
    "    ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95\n",
    "    mp, mr, map50, map5_95 = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
    "    print('COP:',mp, mr, map50,map5_95)\n",
    "    \n",
    "stats = [torch.cat(x, 0).cpu().numpy() for x in zip(*Hybridstate)]  # to numpy\n",
    "if len(stats) and stats[0].any():\n",
    "    tp, fp, p, r, f1, ap, ap_class = ap_per_class(*stats, plot=False, save_dir=None, names={'name':'yolov5s'})\n",
    "    ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95\n",
    "    mp, mr, map50, map5_95 = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
    "    print('CVP:',mp, mr, map50,map5_95)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "N-code-test",
   "language": "python",
   "name": "n-code-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
