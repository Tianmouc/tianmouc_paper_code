{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aefaad7",
   "metadata": {},
   "source": [
    "# Reconstructor\n",
    "\n",
    "note: This model is a bit large, which require about 12GB GPU MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27783c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fc389f",
   "metadata": {},
   "source": [
    "# prepare environment and reconstruction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cdb6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, random,sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../datareader\")\n",
    "from tianmoucv.alg import cal_optical_flow,backWarp,flow_to_image,white_balance\n",
    "from tianmoucv.basic import vizDiff\n",
    "from tianmoucv.nn import warp_fast,interpolate_preprocess\n",
    "from tianmoucv.isp import lyncam_raw_comp,demosaicing_npy\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "##################### Step1. Env Preparation #####################\n",
    "local_rank = 0\n",
    "device = torch.device('cuda:'+str(0))\n",
    "torch.cuda.set_device(0)\n",
    "writer = None \n",
    "master = False \n",
    "\n",
    "###################### Step2. model and data Preparation #############\n",
    "\n",
    "from  model.reconstructor_new import TianmoucRecon\n",
    "\n",
    "CHECKPOINT_DIR =  '../data/ckpts/'\n",
    "CHECKPOINT_PATH_MODEL = '../data/ckpts/unet_reconstruction.ckpt'\n",
    "\n",
    "VALIDATION_BATCH_SIZE = 1\n",
    "TRAINING_CONTINUE = True\n",
    "h = 320\n",
    "w = 640 \n",
    "Val_size   = (w,h)\n",
    "ReconModel = TianmoucRecon(Val_size)\n",
    "ReconModel.load_model(ckpt=CHECKPOINT_PATH_MODEL)\n",
    "ReconModel.to(device)\n",
    "start = time.time()\n",
    "imlist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f6241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tianmoucData import TianmoucDataReader\n",
    "\n",
    "dataset_top1 = \"../data/recon_data\"\n",
    "datasetList = [dataset_top1]\n",
    "\n",
    "key = 'tunnelbyq9_1332ae'\n",
    "key = 'openroad_sync1yh'\n",
    "\n",
    "startID = 50\n",
    "endID = startID + 20\n",
    "\n",
    "dataset = TianmoucDataReader(datasetList,matchkey=key)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=VALIDATION_BATCH_SIZE,\\\n",
    "                                         num_workers=4, pin_memory=False, drop_last = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4cbb1b",
   "metadata": {},
   "source": [
    "# run reconstruction\n",
    "\n",
    "## mode1: ifsingleDirection = True\n",
    "cop0 + (aop0 + ... + aopn) -> reconstructed_RGB\n",
    "\n",
    "## mode1: ifsingleDirection = False\n",
    "cop0 + (aop0 + ... + aopn + ... + aop_N-1) + cop1 -> reconstructed_RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34578df3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "ifsingleDirection = True\n",
    "with torch.no_grad():\n",
    "    validationIndex = 0\n",
    "    for index,sampleRaw in enumerate(dataloader, 0):\n",
    "        if index < startID:\n",
    "            continue\n",
    "        if index > endID:\n",
    "            break\n",
    "        startTime  = time.time()\n",
    "        sample = dict([])\n",
    "        F0 = sampleRaw['F0']\n",
    "        F1 = sampleRaw['F1']\n",
    "        \n",
    "        tsdiff = sampleRaw['tsdiff']\n",
    "        sample['F0'] = F0.permute(0,3,1,2).to(device)\n",
    "        sample['F1'] =  F1.permute(0,3,1,2).to(device)\n",
    "        sample['tsdiff'] = tsdiff.to(device)\n",
    "        \n",
    "        middleTime  = time.time()\n",
    "        F1t, F0,tsdiff= warp_fast(sample,ReconModel,None,h,w,device,ifsingleDirection=ifsingleDirection)\n",
    "        endTime  = time.time()\n",
    "        tsdiff = tsdiff.cpu()\n",
    "        for t in range(25):\n",
    "            retImg1 = F0.cpu()[t,:,:,:]\n",
    "            retImg2 = F1t.cpu()[t,:,:,:]\n",
    "            imageCanve = torch.zeros([3,w*4,h*3])\n",
    "            gapw = w//4\n",
    "            gaoh = h//4\n",
    "            imageCanve[:,gaoh:gaoh+h,gapw:gapw+w]\n",
    "            \n",
    "            sd  = tsdiff[0,1,t,...] * 255      \n",
    "            rgb_sd = vizDiff(sd,thresh=12)\n",
    "                             \n",
    "            td = tsdiff[0,0,t,...] * 255    \n",
    "            rgb_td = vizDiff(td,thresh=12)\n",
    "\n",
    "            img_col1 = torch.cat([retImg1,rgb_td],dim=1)\n",
    "            img_col2 = torch.cat([rgb_sd,retImg2],dim=1) \n",
    "            img = torch.cat([img_col1,img_col2],dim=2)\n",
    "            imlist.append(img)\n",
    "            if t == 12:\n",
    "                plt.figure(figsize=(16,8))\n",
    "                canvas = (img.permute(1,2,0).numpy() * 255).astype(np.uint8).copy()\n",
    "                canvas[0:h,0:w,...] = white_balance(canvas[0:h,0:w,...])\n",
    "                canvas[h:2*h,w:2*w,...] = white_balance(canvas[h:2*h,w:2*w,...])\n",
    "                \n",
    "                cv2.putText(canvas,\"CONE\",(10+0*w,20+0*h),cv2.FONT_HERSHEY_SIMPLEX,0.75,(255,255,255),2)\n",
    "                cv2.putText(canvas,\"TD\",(10+0*w,20+1*h),cv2.FONT_HERSHEY_SIMPLEX,0.75,(255,255,255),2)\n",
    "                cv2.putText(canvas,\"SD\",(10+1*w,20+0*h),cv2.FONT_HERSHEY_SIMPLEX,0.75,(255,255,255),2)\n",
    "                cv2.putText(canvas,\"reconstructed:cone+12aop(~16ms)\",(10+1*w,20+1*h),cv2.FONT_HERSHEY_SIMPLEX,0.75,(255,255,255),2)\n",
    "                plt.imshow(canvas)\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "        \n",
    "        print(validationIndex,'/',endID-startID, ' cost:',endTime-startTime,'s',' run:',middleTime-startTime,'s')\n",
    "        validationIndex += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd07e604",
   "metadata": {},
   "source": [
    "# dump a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb84167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_video(frame_list,name,Val_size=(512,256),Flip=False):\n",
    "    fps = 15          \n",
    "    size = (Val_size[0]*2, Val_size[1]*2) # 需要转为视频的图片的尺寸\n",
    "    #cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    out = cv2.VideoWriter(name,0x7634706d , fps, size)\n",
    "    for frame in frame_list:\n",
    "        frame = (frame[[2,1,0],:,]*255).cpu().permute(1,2,0).numpy() \n",
    "        w = Val_size[0]\n",
    "        h = Val_size[1]\n",
    "        frame[0:h,0:w,...] = white_balance(frame[0:h,0:w,...])\n",
    "        frame[h:2*h,w:2*w,...] = white_balance(frame[h:2*h,w:2*w,...])\n",
    "        if Flip:\n",
    "            frame[0:h,0:w,:] = frame[h:0:-1,0:w,:]\n",
    "            frame[h:2*h,0:w,:] = frame[2*h:h-1:-1,0:w,:]\n",
    "            frame[0:h,w:2*w,:] = frame[h:0:-1,w:2*w,:]\n",
    "            frame[h:2*h,w:2*w,:] = frame[h*2:h-1:-1,w:2*w,:]\n",
    "        \n",
    "        frame = frame.astype(np.uint8)\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "    \n",
    "images_to_video(imlist,'../../results/'+key+'_'+str(validationIndex)+'.mp4',Val_size=(w,h),Flip=False)\n",
    "imlist_fast = []\n",
    "for i in range(len(imlist)//12):\n",
    "    imlist_fast.append(imlist[i*12])\n",
    "\n",
    "images_to_video(imlist_fast,'../../results/'+key+'_'+str(validationIndex)+'_fast.mp4',Val_size=(w,h),Flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce913d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "N-code-test",
   "language": "python",
   "name": "n-code-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
